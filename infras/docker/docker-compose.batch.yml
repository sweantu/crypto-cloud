services:
  spark-master:
    image: custom-spark:3.5.4-java17
    ports:
      - "7077:7077"
      - "8080:8080"
    command: >
      bash -c " /opt/spark/sbin/start-master.sh && tail -f /opt/spark/logs/*"

  spark-worker:
    image: custom-spark:3.5.4-java17
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    command: >
      bash -c " /opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /opt/spark/logs/*"

  airflow:
    image: custom-airflow:2.10.3-python3.11
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow123@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY="Jers0E9_wUUeAcywlKdthfytgqpiO7QsGfk0GMiYwjw="
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=10
      - AIRFLOW__CORE__DEFAULT_TIMEZONE=UTC
      - AIRFLOW_ADMIN_USERNAME=admin
      - AIRFLOW_ADMIN_PASSWORD=admin123
      - AIRFLOW_ADMIN_EMAIL=admin@example.com
      - GLUE_LANDING_JOB=landing_job
      - GLUE_TRANSFORM_JOB=transform_job
      - GLUE_TRANSFORM_JOB_PATTERN_TWO=transform_job_pattern_two
    volumes:
      - ./airflow/dags:/opt/airflow/dags
    ports:
      - "8082:8080"
