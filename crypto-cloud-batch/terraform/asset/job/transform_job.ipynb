{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f7c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from pyspark.errors.exceptions.base import AnalysisException\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ff6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_exists(spark: SparkSession, database: str, table: str) -> bool:\n",
    "    try:\n",
    "        spark.catalog.getTable(f\"{database}.{table}\")\n",
    "        return True\n",
    "    except AnalysisException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f71ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea068f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/anhtu/.pyenv/versions/3.11.11/envs/crypto-cloud-batch/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/anhtu/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/anhtu/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.apache.iceberg#iceberg-aws-bundle added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ab5439aa-3497-4b6f-9e87-4439fce5a0c4;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.1 in central\n",
      "\tfound org.apache.iceberg#iceberg-aws-bundle;1.6.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 111ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-aws-bundle;1.6.1 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.1 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ab5439aa-3497-4b6f-9e87-4439fce5a0c4\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/2ms)\n",
      "25/11/05 20:23:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "project_prefix = \"crypto-cloud-dev-650251698703\"\n",
    "data_lake_bucket_name = \"crypto-cloud-dev-650251698703-data-lake-bucket\"\n",
    "data_lake_iceberg_lock_table_name = \"crypto_cloud_dev_650251698703_iceberg_lock_table\"\n",
    "data_prefix = project_prefix.replace(\"-\", \"_\")\n",
    "\n",
    "landing_date = \"2025-09-27\"\n",
    "symbol = \"ADAUSDT\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Transform Job\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,\"\n",
    "        \"org.apache.iceberg:iceberg-aws-bundle:1.6.1,\"\n",
    "        \"org.apache.hadoop:hadoop-aws:3.3.4\"\n",
    "    )\n",
    "    .config(\"spark.sql.catalog.glue_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.glue_catalog.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\")\n",
    "    .config(\"spark.sql.catalog.glue_catalog.warehouse\", f\"s3a://{data_lake_bucket_name}/\")\n",
    "    .config(\"spark.sql.catalog.glue_catalog.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    .config(\"spark.sql.catalog.glue_catalog.lock.table\", f\"{data_lake_iceberg_lock_table_name}\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "    .config(\"spark.sql.defaultCatalog\", \"glue_catalog\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "    .config(\"spark.sql.columnVector.offheap.enabled\", \"false\")\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"false\")\n",
    "    .config(\"spark.sql.catalog.glue_catalog.read.parquet.vectorization.enabled\", \"false\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-XX:MaxDirectMemorySize=1g\")\n",
    "    .config(\"spark.sql.codegen.wholeStage\", \"false\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481c9d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/05 11:35:49 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = (\n",
    "    f\"s3a://{data_lake_bucket_name}/landing_zone/spot/daily/aggTrades/{symbol}/{landing_date}\"\n",
    ")\n",
    "df = spark.read.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432b14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.withColumn(\"timestamp_date\", F.from_unixtime(F.col(\"timestamp\") / 1_000_000))\n",
    "    .withColumn(\"timestamp_second\", (F.col(\"timestamp\") / 1_000_000).cast(\"long\"))\n",
    "    .withColumn(\"group_id\", (F.col(\"timestamp_second\") / 900).cast(\"long\"))\n",
    "    .withColumn(\"group_date\", F.from_unixtime(F.col(\"group_id\") * 900))\n",
    "    .withColumn(\"transform_date\", F.current_date())\n",
    "    .withColumn(\"transform_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"landing_date\", F.to_date(F.lit(landing_date), \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"symbol\", F.lit(symbol))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55a64e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_db = f\"{data_prefix}_transform_db\"\n",
    "spark.sql(f\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS {transform_db}\n",
    "LOCATION 's3a://{data_lake_bucket_name}/transform_zone/'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0f747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Table crypto_cloud_dev_650251698703_transform_db.aggtrades created for ADAUSDT on 2025-09-27\n"
     ]
    }
   ],
   "source": [
    "aggtrade_table = \"aggtrades\"\n",
    "if table_exists(spark, transform_db, aggtrade_table):\n",
    "    df.writeTo(f\"{transform_db}.{aggtrade_table}\").overwritePartitions()\n",
    "    logger.info(\n",
    "        f\"Table {transform_db}.{aggtrade_table} overwritten for {symbol} on {landing_date}\"\n",
    "    )\n",
    "else:\n",
    "    df.writeTo(f\"{transform_db}.{aggtrade_table}\").tableProperty(\n",
    "        \"format-version\", \"2\"\n",
    "    ).partitionedBy(\"symbol\", \"landing_date\").createOrReplace()\n",
    "    logger.info(f\"Table {transform_db}.{aggtrade_table} created for {symbol} on {landing_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e8fce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_db = f\"{data_prefix}_serving_db\"\n",
    "spark.sql(f\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS {serving_db}\n",
    "LOCATION 's3a://{data_lake_bucket_name}/serving_zone/'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ca862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:SQL Statement:\n",
      "\n",
      "select \n",
      "    group_id,\n",
      "    group_date,\n",
      "    first(timestamp, true) as open_time,\n",
      "    round(first(price, true), 4) as open_price,\n",
      "    round(max(price), 4) as high_price,\n",
      "    round(min(price), 4) as low_price,\n",
      "    round(last(price, true), 4) as close_price,\n",
      "    round(sum(quantity), 1) as volume,\n",
      "    last(timestamp, true) as close_time,\n",
      "    landing_date,\n",
      "    symbol\n",
      "from crypto_cloud_dev_650251698703_transform_db.aggtrades\n",
      "where landing_date = DATE('2025-09-27') AND symbol = 'ADAUSDT'\n",
      "group by group_id, group_date, landing_date, symbol\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_stmt = f\"\"\"\n",
    "select \n",
    "    group_id,\n",
    "    group_date,\n",
    "    first(timestamp, true) as open_time,\n",
    "    round(first(price, true), 4) as open_price,\n",
    "    round(max(price), 4) as high_price,\n",
    "    round(min(price), 4) as low_price,\n",
    "    round(last(price, true), 4) as close_price,\n",
    "    round(sum(quantity), 1) as volume,\n",
    "    last(timestamp, true) as close_time,\n",
    "    landing_date,\n",
    "    symbol\n",
    "from {transform_db}.{aggtrade_table}\n",
    "where landing_date = DATE('{landing_date}') AND symbol = '{symbol}'\n",
    "group by group_id, group_date, landing_date, symbol\n",
    "\"\"\"\n",
    "logger.info(f\"SQL Statement:\\n{sql_stmt}\")\n",
    "df_kline = spark.sql(sql_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c4e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Table crypto_cloud_dev_650251698703_serving_db.klines created for ADAUSDT on 2025-09-27\n"
     ]
    }
   ],
   "source": [
    "klines_table = \"klines\"\n",
    "if table_exists(spark, serving_db, klines_table):\n",
    "    df_kline.writeTo(f\"{serving_db}.{klines_table}\").overwritePartitions()\n",
    "    logger.info(f\"Table {serving_db}.{klines_table} overwritten for {symbol} on {landing_date}\")\n",
    "else:\n",
    "    df_kline.writeTo(f\"{serving_db}.{klines_table}\").tableProperty(\n",
    "        \"format-version\", \"2\"\n",
    "    ).partitionedBy(\"symbol\", \"landing_date\").createOrReplace()\n",
    "    logger.info(f\"Table {serving_db}.{klines_table} created for {symbol} on {landing_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37efe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+----------+----------+---------+-----------+--------+----------------+------------+-------+\n",
      "|group_id|         group_date|       open_time|open_price|high_price|low_price|close_price|  volume|      close_time|landing_date| symbol|\n",
      "+--------+-------------------+----------------+----------+----------+---------+-----------+--------+----------------+------------+-------+\n",
      "| 1954368|2025-09-27 00:00:00|1758931200686229|    0.7918|    0.7918|   0.7897|     0.7901|465779.1|1758932095846561|  2025-09-27|ADAUSDT|\n",
      "| 1954369|2025-09-27 00:15:00|1758932100583189|    0.7902|    0.7924|     0.79|     0.7911|163062.6|1758932997788221|  2025-09-27|ADAUSDT|\n",
      "| 1954370|2025-09-27 00:30:00|1758933000808905|    0.7912|     0.792|   0.7905|     0.7913|202817.4|1758933895280530|  2025-09-27|ADAUSDT|\n",
      "| 1954371|2025-09-27 00:45:00|1758933900464103|    0.7913|    0.7927|   0.7899|     0.7923|434212.2|1758934797111165|  2025-09-27|ADAUSDT|\n",
      "| 1954372|2025-09-27 01:00:00|1758934803068992|    0.7924|    0.7927|   0.7902|     0.7913|555784.6|1758935692008887|  2025-09-27|ADAUSDT|\n",
      "| 1954373|2025-09-27 01:15:00|1758935700968789|    0.7912|    0.7922|   0.7882|     0.7897|550528.6|1758936598705957|  2025-09-27|ADAUSDT|\n",
      "| 1954374|2025-09-27 01:30:00|1758936600409086|    0.7898|    0.7905|   0.7886|     0.7899|405461.3|1758937496408758|  2025-09-27|ADAUSDT|\n",
      "| 1954375|2025-09-27 01:45:00|1758937508308921|      0.79|    0.7907|   0.7898|     0.7903|127489.5|1758938399129296|  2025-09-27|ADAUSDT|\n",
      "| 1954376|2025-09-27 02:00:00|1758938402553238|    0.7903|     0.791|    0.789|     0.7909|387130.3|1758939294919265|  2025-09-27|ADAUSDT|\n",
      "| 1954377|2025-09-27 02:15:00|1758939300355357|    0.7909|    0.7912|   0.7885|     0.7896|273607.2|1758940195292187|  2025-09-27|ADAUSDT|\n",
      "| 1954378|2025-09-27 02:30:00|1758940200309296|    0.7896|    0.7912|   0.7889|     0.7911|179209.4|1758941080407977|  2025-09-27|ADAUSDT|\n",
      "| 1954379|2025-09-27 02:45:00|1758941104779273|    0.7912|    0.7917|   0.7892|     0.7892|296011.2|1758941987171987|  2025-09-27|ADAUSDT|\n",
      "| 1954380|2025-09-27 03:00:00|1758942004432931|    0.7893|    0.7916|    0.789|     0.7903|414739.8|1758942899873022|  2025-09-27|ADAUSDT|\n",
      "| 1954381|2025-09-27 03:15:00|1758942900129440|    0.7902|    0.7936|     0.79|     0.7933|380854.9|1758943795149448|  2025-09-27|ADAUSDT|\n",
      "| 1954382|2025-09-27 03:30:00|1758943800166342|    0.7933|    0.7941|   0.7928|     0.7937|514478.1|1758944697400288|  2025-09-27|ADAUSDT|\n",
      "| 1954383|2025-09-27 03:45:00|1758944700708797|    0.7936|    0.7939|   0.7919|     0.7923|409480.0|1758945598019653|  2025-09-27|ADAUSDT|\n",
      "| 1954384|2025-09-27 04:00:00|1758945602518439|    0.7923|     0.793|   0.7908|      0.791|404950.0|1758946495095558|  2025-09-27|ADAUSDT|\n",
      "| 1954385|2025-09-27 04:15:00|1758946500267678|     0.791|    0.7931|   0.7909|      0.793|312491.6|1758947379908581|  2025-09-27|ADAUSDT|\n",
      "| 1954386|2025-09-27 04:30:00|1758947400608601|     0.793|    0.7934|    0.792|     0.7921|377653.4|1758948294033041|  2025-09-27|ADAUSDT|\n",
      "| 1954387|2025-09-27 04:45:00|1758948324484620|    0.7921|    0.7921|   0.7908|     0.7917|448336.2|1758949196581383|  2025-09-27|ADAUSDT|\n",
      "+--------+-------------------+----------------+----------+----------+---------+-----------+--------+----------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serving_db = f\"{data_prefix}_serving_db\"\n",
    "klines_table = \"klines\"\n",
    "spark.sql(f\"\"\"\n",
    "select * from {serving_db}.{klines_table} order by group_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323a9ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+----------+----------+---------+-----------+--------+----------------+------------+-------+------+------+---------+-----------------+\n",
      "|group_id|group_date         |open_time       |open_price|high_price|low_price|close_price|volume  |close_time      |landing_date|symbol |ema7  |ema20 |trend    |pattern          |\n",
      "+--------+-------------------+----------------+----------+----------+---------+-----------+--------+----------------+------------+-------+------+------+---------+-----------------+\n",
      "|1954413 |2025-09-27 11:15:00|1758971700405060|0.7837    |0.7853    |0.7837   |0.785      |121594.4|1758972591323187|2025-09-27  |ADAUSDT|0.7835|0.784 |downtrend|bullish engulfing|\n",
      "|1954445 |2025-09-27 19:15:00|1759000502967967|0.7803    |0.7823    |0.78     |0.7821     |95233.0 |1759001384883232|2025-09-27  |ADAUSDT|0.7808|0.7817|downtrend|bullish engulfing|\n",
      "+--------+-------------------+----------------+----------+----------+---------+-----------+--------+----------------+------------+-------+------+------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serving_db = f\"{data_prefix}_serving_db\"\n",
    "pattern_two_table = \"pattern_two\"\n",
    "spark.sql(f\"\"\"\n",
    "select * from {serving_db}.{pattern_two_table} where pattern is not null\n",
    "\"\"\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a88965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
