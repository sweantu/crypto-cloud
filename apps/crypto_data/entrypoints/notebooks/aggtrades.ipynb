{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300b7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql import functions as F\n",
    "from shared_lib.s3 import upload_to_s3\n",
    "from shared_lib.file import download_file, remove_file, extract_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcae04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_date = \"2025-09-28\"\n",
    "symbol = \"ADAUSDT\"\n",
    "\n",
    "DATA_LAKE_BUCKET = os.getenv(\"DATA_LAKE_BUCKET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aead3d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:shared_lib.file:Downloading https://data.binance.vision/data/spot/daily/aggTrades/ADAUSDT/ADAUSDT-aggTrades-2025-09-28.zip -> /tmp/data/raw/ADAUSDT-aggTrades-2025-09-28.zip\n",
      "INFO:shared_lib.file:Downloaded /tmp/data/raw/ADAUSDT-aggTrades-2025-09-28.zip 0.87MB completed in 0.449 seconds\n",
      "INFO:shared_lib.file:Extracting /tmp/data/raw/ADAUSDT-aggTrades-2025-09-28.zip -> /tmp/data/raw/unzipped_data\n",
      "INFO:shared_lib.file:Extracted CSV: /tmp/data/raw/unzipped_data/ADAUSDT-aggTrades-2025-09-28.csv in 0.013 seconds\n"
     ]
    }
   ],
   "source": [
    "script_dir = \"/tmp/data/raw\"\n",
    "extract_dir = os.path.join(script_dir, \"unzipped_data\")\n",
    "url = f\"https://data.binance.vision/data/spot/daily/aggTrades/{symbol}/{symbol}-aggTrades-{landing_date}.zip\"\n",
    "zip_path = os.path.join(script_dir, url.split(\"/\")[-1])\n",
    "\n",
    "download_file(url, zip_path)\n",
    "csv_path = extract_file(extract_dir, zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36619a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 16:01:56 WARN Utils: Your hostname, Nguyens-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.29 instead (on interface en0)\n",
      "25/12/05 16:01:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/anhtu/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/anhtu/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e32ad6e8-eba6-4cb6-a783-8ccf8e487985;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/anhtu/Code/example/crypto-cloud/venv/spark_jobs/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 87ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e32ad6e8-eba6-4cb6-a783-8ccf8e487985\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/2ms)\n",
      "25/12/05 16:01:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Landing Job\") # type: ignore\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    # local mode optimizations to reduce memory consumption\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "    .config(\"spark.sql.columnVector.offheap.enabled\", \"false\")\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"false\")\n",
    "    .config(\"spark.sql.catalog.glue_catalog.read.parquet.vectorization.enabled\", \"false\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-XX:MaxDirectMemorySize=1g\")\n",
    "    .config(\"spark.sql.codegen.wholeStage\", \"false\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\")\n",
    "    .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b2b5462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in environment variables.\n",
      "INFO:shared_lib.s3:Uploaded to s3://crypto-cloud-dev-650251698703-data-lake-bucket/raw_zone/ADAUSDT-aggTrades-2025-09-28.csv\n",
      "25/12/05 16:01:59 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "s3_url = upload_to_s3(DATA_LAKE_BUCKET, csv_path)\n",
    "\n",
    "schema = types.StructType(\n",
    "    [\n",
    "        types.StructField(\"agg_trade_id\", types.LongType(), True),\n",
    "        types.StructField(\"price\", types.DoubleType(), True),\n",
    "        types.StructField(\"quantity\", types.DoubleType(), True),\n",
    "        types.StructField(\"first_trade_id\", types.LongType(), True),\n",
    "        types.StructField(\"last_trade_id\", types.LongType(), True),\n",
    "        types.StructField(\"timestamp\", types.LongType(), True),\n",
    "        types.StructField(\"is_buyer_maker\", types.BooleanType(), True),\n",
    "        types.StructField(\"is_best_match\", types.BooleanType(), True),\n",
    "    ]\n",
    ")\n",
    "df = spark.read.option(\"header\", \"false\").schema(schema).csv(s3_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb121b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"ingest_date\", F.current_date()).withColumn(\n",
    "    \"ingest_timestamp\", F.current_timestamp()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c18ab50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Parquet written to: s3://crypto-cloud-dev-650251698703-data-lake-bucket/landing_zone/spot/daily/aggTrades/ADAUSDT/2025-09-28\n"
     ]
    }
   ],
   "source": [
    "output_path = (\n",
    "    f\"s3://{DATA_LAKE_BUCKET}/landing_zone/spot/daily/aggTrades/{symbol}/{landing_date}\"\n",
    ")\n",
    "df.write.mode(\"overwrite\").parquet(output_path)\n",
    "logger.info(f\"Parquet written to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9735e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:shared_lib.file:/tmp/data/raw/unzipped_data/ADAUSDT-aggTrades-2025-09-28.csv removed\n",
      "INFO:shared_lib.file:/tmp/data/raw/ADAUSDT-aggTrades-2025-09-28.zip removed\n",
      "INFO:__main__:✅ Landing job completed successfully.\n"
     ]
    }
   ],
   "source": [
    "remove_file(csv_path)\n",
    "remove_file(zip_path)\n",
    "logger.info(\"✅ Landing job completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2667b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------+--------------+-------------+----------------+--------------+-------------+-----------+--------------------------+\n",
      "|agg_trade_id|price |quantity|first_trade_id|last_trade_id|timestamp       |is_buyer_maker|is_best_match|ingest_date|ingest_timestamp          |\n",
      "+------------+------+--------+--------------+-------------+----------------+--------------+-------------+-----------+--------------------------+\n",
      "|411153010   |0.781 |6016.6  |711818877     |711818882    |1759017601892334|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153011   |0.7811|4051.1  |711818883     |711818888    |1759017602554502|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153012   |0.7811|2424.3  |711818889     |711818891    |1759017602555523|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153013   |0.7812|49.1    |711818892     |711818896    |1759017602611301|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153014   |0.7812|53.1    |711818897     |711818897    |1759017602646473|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153015   |0.7812|6.5     |711818898     |711818898    |1759017602962781|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153016   |0.7811|15.0    |711818899     |711818899    |1759017602969225|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153017   |0.7812|640.0   |711818900     |711818900    |1759017604563744|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153018   |0.7811|1891.6  |711818901     |711818901    |1759017605615690|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153019   |0.7813|26.8    |711818902     |711818904    |1759017612705837|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153020   |0.7813|120.8   |711818905     |711818905    |1759017613049132|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153021   |0.7814|138.2   |711818906     |711818912    |1759017613683112|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153022   |0.7814|12.3    |711818913     |711818913    |1759017614543976|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153023   |0.7815|7.0     |711818914     |711818914    |1759017614776319|false         |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153024   |0.7814|91.8    |711818915     |711818915    |1759017614781170|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153025   |0.7814|112.6   |711818916     |711818919    |1759017616649056|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153026   |0.7814|138.9   |711818920     |711818921    |1759017616651217|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153027   |0.7813|138.9   |711818922     |711818922    |1759017616651930|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153028   |0.7813|251.5   |711818923     |711818923    |1759017616652974|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "|411153029   |0.7813|112.6   |711818924     |711818928    |1759017616817052|true          |true         |2025-12-05 |2025-12-05 09:02:01.509167|\n",
      "+------------+------+--------+--------------+-------------+----------------+--------------+-------------+-----------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(output_path).show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342ef34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_jobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
